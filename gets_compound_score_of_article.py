# -*- coding: utf-8 -*-
"""Gets compound score of article

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lHS_QyVxCV-gAU6TVTLzfunilz5mOmMY
"""

#import our modules and packages that we will need to scrape a website
!pip install requests beautifulsoup4
from urllib.request import Request, urlopen
import csv
from bs4 import BeautifulSoup
import requests
import re
import time
from google.colab import files


# pre-processing of text
import string
import re
from sklearn.feature_extraction import _stop_words


# library for object reorganization
import nltk
nltk.download('punkt')

# sentiment library
!pip install vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()

"""Preprocess words from scrape function"""

# function that preprocesses text and makes it more computable
stopwords = _stop_words.ENGLISH_STOP_WORDS
def clean(doc): # doc is a string of text
    doc = doc.replace('"', "") # This text contains a lot of quotes.
    doc = "".join([char for char in doc if char not in string.punctuation and not char.isdigit()])
    doc = " ".join([token.lower() for token in doc.split() if token not in stopwords])
    # remove punctuation and numbers
    return doc

"""gets average sentiment value (range 0-1, 0=negative, 1=positive) from a direct article URL in coinbase"""

def average_sentiment_article(url): # parser is setup for specifically coin desk html

  # give a header so site doesn't block us
  headers = {
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36",
    "from": "CoinDesk"}

  # request page and parse url using beautiful soup
  page = requests.get(url, headers=headers) #response 200 with www.coindesk
  page_content = page.content
  soup = BeautifulSoup(page_content, "html.parser")
  article_content = soup.find("div", class_="contentstyle__StyledWrapper-g5cdrh-0 ipXuoZ composer-content")

  if article_content is not None:

      # Extract all the text from the article content
      text = article_content.get_text()

      # break up text into sentence chunks that we can do a sentiment analysis on
      sentences = nltk.sent_tokenize(text)

      # preprocesses string using preprocess function I made earlier
      text = clean(text) #this is currently not working - nltk doesn't work with clean function with how I have code setup

      # get the average compound score of the article
      sum = 0
      compound_scores = []
      for sentence in sentences:
          scores = analyzer.polarity_scores(sentence)
          compound_scores.append(scores['compound'])

      for compound_score in compound_scores:
        sum = sum + compound_score

      average_compound_score = sum / len(compound_scores)
      return average_compound_score

  else:
    not_found = 'article not found'
    return not_found

average_sentiment_article('https://www.coindesk.com/policy/2023/06/16/tethers-banking-relationships-commercial-paper-exposure-detailed-in-newly-released-legal-documents/')

"""grabs all hrefs from html of homepage url"""

def href_finder(homepage_url):
  # request url from site and open it
  req = Request(homepage_url)

  # user agent header
  req = Request(homepage_url, headers={"User-Agent": "Chrome/5.0"})
  html_page = urlopen(req)

  # run lxml beautifulsoup library on html
  soup = BeautifulSoup(html_page, "html.parser")

  # create empty list that will contain all links to articles
  links = []

  # loops through all of the <a href> tags and adds https so they show up as links
  for link in soup.findAll('a', attrs={'href': re.compile("^https://")}):
    links.append(link.get('href'))

  return links

"""trying to get sentiment score of all hrefs found using average_sentiment_article function. From here I can average all of the sentiments to get the average bitcoin sentiment value."""

list_of_sentiment_scores = []
for element in href_finder("https://www.coindesk.com/"):
  # if average_sentiment_article(element)
  average_sentiment_article(element)